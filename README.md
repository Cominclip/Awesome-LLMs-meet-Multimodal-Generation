# LLMs-VisualGen


## Image Editing

+ **LLM Blueprint: Enabling Text-to-Image Generation with Complex and Detailed Prompts** (Oct 2023)\
Gani, Hanan, et al.\
[![Paper](https://img.shields.io/badge/arXiv-b31b1b.svg)](https://arxiv.org/abs/2310.10640)

+ **Making Multimodal Generation Easier: When Diffusion Models Meet LLMs** (Oct 2023)\
Qu, Leigang, et al.\
[![Paper](https://img.shields.io/badge/arXiv-b31b1b.svg)](https://arxiv.org/abs/2310.08949v1)
[![Code](https://img.shields.io/github/stars/zxy556677/EasyGen.svg?style=social&label=Star)](https://github.com/zxy556677/EasyGen)


+ **CHATEDIT: Towards Multi-turn Interactive Facial Image Editing via Dialogue** (Mar 2023)\
Cui, Xing, et al.\
[![Paper](https://img.shields.io/badge/arXiv-b31b1b.svg)](https://arxiv.org/abs/2303.11108)
[![Code](https://img.shields.io/github/stars/cuixing100876/ChatEdit.svg?style=social&label=Star)](https://github.com/cuixing100876/ChatEdit)

+ **Guiding Instruction-based Image Editing via Multimodal Large Language Models** (Sep 2023)\
Fu, Tsu-Jui, et al.\
[![Paper](https://img.shields.io/badge/arXiv-b31b1b.svg)](https://arxiv.org/abs/2309.17102v1)
[![Code](https://img.shields.io/github/stars/tsujuifu/pytorch_mgie.svg?style=social&label=Star)](https://github.com/tsujuifu/pytorch_mgie)
[![Website](https://img.shields.io/badge/Website-9cf)](https://mllm-ie.github.io/)

+ **Interactive Image Manipulation with Complex Text Instructions** (Nov 2022)\
Brooks, Tim, Aleksander Holynski, and Alexei A. Efros. WACV 2023.\
[![Paper](https://img.shields.io/badge/arXiv-b31b1b.svg)](https://arxiv.org/abs/2211.15352)

+ **InstructPix2Pix: Learning to Follow Image Editing Instructions** (Jan 2022)\
Brooks, Tim, Aleksander Holynski, and Alexei A. Efros. CVPR 2023 (Highlight).\
[![Paper](https://img.shields.io/badge/arXiv-b31b1b.svg)](https://arxiv.org/abs/2211.09800)
[![Code](https://img.shields.io/github/stars/timothybrooks/instruct-pix2pix.svg?style=social&label=Star)](https://github.com/timothybrooks/instruct-pix2pix)
[![Website](https://img.shields.io/badge/Website-9cf)](https://www.timothybrooks.com/instruct-pix2pix)


## Image Generation
+ **Generating Images with Multimodal Language Models** (Oct 2023)\
Koh, Jing Yu, Daniel Fried, and Ruslan Salakhutdinov. NeurIPS 2023.\
[![Paper](https://img.shields.io/badge/arXiv-b31b1b.svg)](https://arxiv.org/abs/2305.17216)
[![Code](https://img.shields.io/github/stars/kohjingyu/gill.svg?style=social&label=Star)](https://github.com/kohjingyu/gill)
[![Website](https://img.shields.io/badge/Website-9cf)](https://layoutgpt.github.io/)

+ **LayoutGPT: Compositional Visual Planning and Generation with Large Language Models** (Oct 2023)\
Feng, Weixi, et al. NeurIPS 2023.\
[![Paper](https://img.shields.io/badge/arXiv-b31b1b.svg)](https://arxiv.org/abs/2305.15393)
[![Code](https://img.shields.io/github/stars/kohjingyu/gill.svg?style=social&label=Star)](https://github.com/weixi-feng/LayoutGPT)
[![Website](https://img.shields.io/badge/Website-9cf)](https://jykoh.com/gill)

+ **GLayoutLLM-T2I: Eliciting Layout Guidance from LLM for Text-to-Image Generation** (Aug 2023)\
Qu, Leigang, et al. ACM MM 2023.\
[![Paper](https://img.shields.io/badge/arXiv-b31b1b.svg)](https://arxiv.org/abs/2308.05095)
[![Code](https://img.shields.io/github/stars/LayoutLLM-T2I/LayoutLLM-T2I.svg?style=social&label=Star)](https://github.com/LayoutLLM-T2I/LayoutLLM-T2I)
[![Website](https://img.shields.io/badge/Website-9cf)](https://layoutllm-t2i.github.io/)

+ **LLM-grounded Diffusion: Enhancing Prompt Understanding of Text-to-Image Diffusion Models with Large Language Models** (May 2023)\
Lian, Long, et al.\
[![Paper](https://img.shields.io/badge/arXiv-b31b1b.svg)](https://arxiv.org/abs/2305.13655)
[![Code](https://img.shields.io/github/stars/TonyLianLong/LLM-groundedDiffusion.svg?style=social&label=Star)](https://github.com/TonyLianLong/LLM-groundedDiffusion)
[![Website](https://img.shields.io/badge/Website-9cf)](https://llm-grounded-diffusion.github.io/)

+ **Controllable Text-to-Image Generation with GPT-4** (May 2023)\
Lian, Long, et al.\
[![Paper](https://img.shields.io/badge/arXiv-b31b1b.svg)](https://arxiv.org/abs/2305.18583)
[![Website](https://img.shields.io/badge/Website-9cf)](https://github.com/tianjunz/Control-GPT)

+ **High-Resolution Image Synthesis with Latent Diffusion Models** (Dec 2021)\
Rombach, Robin, et al. CVPR 2022 (Oral).\
[![Paper](https://img.shields.io/badge/arXiv-b31b1b.svg)](https://arxiv.org/abs/2112.10752)
[![Code](https://img.shields.io/github/stars/CompVis/stable-diffusion.svg?style=social&label=Star)](https://github.com/CompVis/stable-diffusion)
[![Website](https://img.shields.io/badge/Website-9cf)](https://ommer-lab.com/research/latent-diffusion-models/)

+ **Making LLaMA SEE and Draw with SEED Tokenizer** (Oct 2023)\
Yuying Ge, Sijie Zhao, et al.\
[![Paper](https://img.shields.io/badge/arXiv-b31b1b.svg)](https://arxiv.org/abs/2307.08041)
[![Code](https://img.shields.io/github/stars/CompVis/stable-diffusion.svg?style=social&label=Star)](https://github.com/AILab-CVC/SEED)
[![Website](https://img.shields.io/badge/Website-9cf)](https://ailab-cvc.github.io/seed/)

+ **DreamLLM: Synergistic Multimodal Comprehension and Creation** (Oct 2023)\
Dong, et al.\
[![Paper](https://img.shields.io/badge/arXiv-b31b1b.svg)](https://arxiv.org/abs/2309.11499)
[![Code](https://img.shields.io/github/stars/CompVis/stable-diffusion.svg?style=social&label=Star)](https://github.com/RunpeiDong/DreamLLM/tree/master)
[![Website](https://img.shields.io/badge/Website-9cf)](https://dreamllm.github.io/)

## Video Editing
+ **Pix2Video: Video Editing using Image Diffusion** (Mar 2023)\
Ceylan, Duygu, Chun-Hao P. Huang, and Niloy J. Mitra. ICCV 2023\
[![Paper](https://img.shields.io/badge/arXiv-b31b1b.svg)](https://arxiv.org/abs/2303.12688)
[![Code](https://img.shields.io/github/stars/duyguceylan/pix2video.svg?style=social&label=Star)](https://github.com/duyguceylan/pix2video)
[![Website](https://img.shields.io/badge/Website-9cf)](https://duyguceylan.github.io/pix2video.github.io/)

## Video Generation
+ **LLM-grounded Video Diffusion Models** (Sep 2023)\
Lian, Long, et al.\
[![Paper](https://img.shields.io/badge/arXiv-b31b1b.svg)](https://arxiv.org/abs/2309.17444)
[![Code](https://img.shields.io/github/stars/TonyLianLong/LLM-groundedVideoDiffusion.svg?style=social&label=Star)](https://github.com/TonyLianLong/LLM-groundedVideoDiffusion)
[![Website](https://img.shields.io/badge/Website-9cf)](https://llm-grounded-video-diffusion.github.io/)

+ **Empowering Dynamics-aware Text-to-Video Diffusion with Large Language Models** (Aug 2023)\
Fei, Hao, et al.\
[![Paper](https://img.shields.io/badge/arXiv-b31b1b.svg)](https://arxiv.org/abs/2308.13812)
[![Code](https://img.shields.io/github/stars/scofield7419/Dysen.svg?style=social&label=Star)](https://github.com/scofield7419/Dysen)
[![Website](https://img.shields.io/badge/Website-9cf)](http://haofei.vip/Dysen-VDM/)

+ **VideoComposer: Compositional Video Synthesis with Motion Controllability** (Jun 2023)\
Wang, Xiang, et al.\
[![Paper](https://img.shields.io/badge/arXiv-b31b1b.svg)](https://arxiv.org/abs/2306.02018)
[![Code](https://img.shields.io/github/stars/damo-vilab/videocomposer.svg?style=social&label=Star)](https://github.com/damo-vilab/videocomposer)
[![Website](https://img.shields.io/badge/Website-9cf)](https://videocomposer.github.io/)

+ **Large Language Models are Frame-level Directors for Zero-shot Text-to-Video Generation** (May 2023)\
Hong, Susung, et al.\
[![Paper](https://img.shields.io/badge/arXiv-b31b1b.svg)](https://arxiv.org/abs/2305.14330)
[![Code](https://img.shields.io/github/stars/KU-CVLAB/DirecT2V.svg?style=social&label=Star)](https://github.com/KU-CVLAB/DirecT2V)

+ **VideoFusion: Decomposed Diffusion Models for High-Quality Video Generation** (Mar 2023)\
Luo, Zhengxiong, et al. CVPR 2023.\
[![Paper](https://img.shields.io/badge/arXiv-b31b1b.svg)](https://arxiv.org/abs/2303.08320)

## Audio Generation
+ **AudioPaLM: A Large Language Model That Can Speak and Listen** (Jun 2023)\
Rubenstein, Paul K., et al. \
[![Paper](https://img.shields.io/badge/arXiv-b31b1b.svg)](https://arxiv.org/abs/2306.12925)
[![Website](https://img.shields.io/badge/Website-9cf)](https://google-research.github.io/seanet/audiopalm/examples/)

+ **Simple and Controllable Music Generation** (Jun 2023)\
Copet, Jade, et al. \
[![Paper](https://img.shields.io/badge/arXiv-b31b1b.svg)](https://arxiv.org/abs/2306.05284)
[![Code](https://img.shields.io/github/stars/facebookresearch/audiocraft.svg?style=social&label=Star)](https://github.com/facebookresearch/audiocraft)
[![Website](https://img.shields.io/badge/Website-9cf)](https://google-research.github.io/seanet/audiopalm/examples/)

