# LLMs-VisualGen


## Image Editing
+ **LLM Blueprint: Enabling Text-to-Image Generation with Complex and Detailed Prompts** (Oct 2023)\
Gani, Hanan, et al.\
[![Paper](https://img.shields.io/badge/arXiv-b31b1b.svg)](https://arxiv.org/abs/2310.10640)

+ **CHATEDIT: Towards Multi-turn Interactive Facial Image Editing via Dialogue** (Oct 2023)\
Cui, Xing, et al.\
[![Code](https://img.shields.io/github/stars/cuixing100876/ChatEdit.svg?style=social&label=Star)](https://github.com/cuixing100876/ChatEdit)
[![Paper](https://img.shields.io/badge/arXiv-b31b1b.svg)](https://arxiv.org/pdf/2303.11108.pdf)

+ **Guiding Instruction-based Image Editing via Multimodal Large Language Models** (Sep 2023)\
Fu, Tsu-Jui, et al.\
[![Paper](https://img.shields.io/badge/arXiv-b31b1b.svg)](https://arxiv.org/pdf/2309.17102.pdf)
[![Website](https://img.shields.io/badge/Website-9cf)](https://mllm-ie.github.io/)

+ **Interactive Image Manipulation with Complex Text Instructions** (Nov 2022)\
Brooks, Tim, Aleksander Holynski, and Alexei A. Efros. WACV 2023.\
[![Paper](https://img.shields.io/badge/arXiv-b31b1b.svg)](https://arxiv.org/pdf/2211.15352.pdf)

+ **InstructPix2Pix: Learning to Follow Image Editing Instructions** (Jan 2022)\
Brooks, Tim, Aleksander Holynski, and Alexei A. Efros. CVPR 2023 (Highlight).\
[![Code](https://img.shields.io/github/stars/timothybrooks/instruct-pix2pix.svg?style=social&label=Star)](https://github.com/timothybrooks/instruct-pix2pix)
[![Paper](https://img.shields.io/badge/arXiv-b31b1b.svg)](https://arxiv.org/pdf/2211.09800.pdf)
[![Website](https://img.shields.io/badge/Website-9cf)](https://www.timothybrooks.com/instruct-pix2pix)


## Image Generation
+ **Generating Images with Multimodal Language Models** (Oct 2023)\
Koh, Jing Yu, Daniel Fried, and Ruslan Salakhutdinov. NeurIPS 2023.\
[![Code](https://img.shields.io/github/stars/kohjingyu/gill.svg?style=social&label=Star)](https://github.com/kohjingyu/gill)
[![Paper](https://img.shields.io/badge/arXiv-b31b1b.svg)](https://arxiv.org/abs/2310.15169)
[![Website](https://img.shields.io/badge/Website-9cf)](https://jykoh.com/gill)

+ **LLM-grounded Diffusion: Enhancing Prompt Understanding of Text-to-Image Diffusion Models with Large Language Models** (May 2023)\
Lian, Long, et al.\
[![Code](https://img.shields.io/github/stars/TonyLianLong/LLM-groundedDiffusion.svg?style=social&label=Star)](https://github.com/TonyLianLong/LLM-groundedDiffusion)
[![Paper](https://img.shields.io/badge/arXiv-b31b1b.svg)](https://arxiv.org/pdf/2305.13655.pdf)
[![Website](https://img.shields.io/badge/Website-9cf)](https://llm-grounded-diffusion.github.io/)

+ **High-Resolution Image Synthesis with Latent Diffusion Models** (Dec 2021)\
Rombach, Robin, et al. CVPR 2022 (Oral).\
[![Code](https://img.shields.io/github/stars/CompVis/stable-diffusion.svg?style=social&label=Star)](https://github.com/CompVis/stable-diffusion)
[![Paper](https://img.shields.io/badge/arXiv-b31b1b.svg)](https://arxiv.org/pdf/2112.10752.pdf)
[![Website](https://img.shields.io/badge/Website-9cf)](https://ommer-lab.com/research/latent-diffusion-models/)

## Video Editing

## Video Generation
+ **LLM-grounded Video Diffusion Models** (Sep 2023)\
Lian, Long, et al.\
[![Code](https://img.shields.io/github/stars/TonyLianLong/LLM-groundedVideoDiffusion.svg?style=social&label=Star)](https://github.com/TonyLianLong/LLM-groundedVideoDiffusion)
[![Paper](https://img.shields.io/badge/arXiv-b31b1b.svg)](https://arxiv.org/pdf/2309.17444.pdf)
[![Website](https://img.shields.io/badge/Website-9cf)](https://llm-grounded-video-diffusion.github.io/)

